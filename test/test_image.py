import json
import pathlib
import shutil
import subprocess
import time

import socket
from contextlib import closing

import pytest


@pytest.fixture(params=pathlib.Path(__file__).parent.glob("*.log"))
def log_file(request, tmp_path):
    """copy log and expected files to a temp dir"""
    # determine the names
    tmp_log = tmp_path / request.param.name
    expected = get_expected_name(request.param)
    tmp_expected = tmp_path / expected.name

    # copy the files
    shutil.copyfile(request.param, tmp_log)
    shutil.copyfile(expected, tmp_expected)
    return tmp_log


def get_expected_name(logfile):
    """get the name of the file with the expected json"""
    return logfile.with_name(logfile.stem + "-expected.json")


def read_file(filename):
    """Reads a file containing one JSON object per line into a list of dicts"""
    with open(filename) as f:
        lines = [json.loads(line) for line in f.readlines()]
    for line in lines:
        # host is generated by logstash, and will change run to run
        del line["host"]
    return lines


def test_logstash_valid_config(image):
    """Run logstash configtest, relying on exceptions for failures"""
    subprocess.check_call(
        [
            "docker",
            "run",
            "--rm",
            "-e",
            "AWS_SECRET_ACCESS_KEY=NOTAREALKEY",
            "-e",
            "S3_REGION=us-west-2",
            "-e",
            "S3_BUCKET=a-random-bucket",
            "-e",
            "S3_PREFIX=a_prefix",
            "-e",
            "ELASTICSEARCH_INDEX=logs-%{+YYYY.MM.dd}",
            "-e",
            "ELASTICSEARCH_HOSTS=host1.example.gov,host2.example.gov",
            image,
            "--config.test_and_exit",
        ]
    )


def test_log_parsing(log_file, image):
    container = f"s3test-{log_file.stem}"
    subprocess.check_call(
        [
            "docker",
            "run",
            "-d",
            "-v",
            f"{log_file.parent}:/logs",
            "-e",
            f"LOGSTASH_READ_FROM_FILE=/logs/{log_file.name}",
            "-e",
            f"LOGSTASH_OUT_FILE=/logs/{log_file.stem}.json",
            "--name",
            container,
            image,
        ]
    )

    counter = 120
    while counter > 0 and log_file.exists():
        time.sleep(2)
        counter -= 2
    subprocess.run(["docker", "stop", container])
    subprocess.run(["docker", "rm", container])
    output_file = log_file.with_suffix(".json")
    expected_file = get_expected_name(log_file)
    l1 = read_file(output_file)
    l2 = read_file(expected_file)
    # kind of silly. We know these are lists of dicts.
    # If they're different lengths, pytest will give us a nice summary.
    # If they're the same length, diff the dicts one-by-one so we get a
    # more readable output of which elements in the dicts are actually different.
    if len(l1) != len(l2):
        assert l1 == l2
    for counter, _ in enumerate(l1):
        assert l1[counter] == l2[counter]


def test_correct_ports_exposed(image):
    port_map = subprocess.check_output(
        ["docker", "inspect", "--format", "{{json .Config.ExposedPorts}}", image]
    )
    port_map = port_map.decode().strip()
    ports = json.loads(port_map)
    assert ports == {"9600/tcp": {}}


def test_port_really_listens(image):
    container = subprocess.check_output(
        [
            "docker",
            "run",
            "-d",
            "-p",
            "127.0.0.1::9600",
            "-e",
            f"LOGSTASH_READ_FROM_FILE=/dev/random",
            "-e",
            f"LOGSTASH_OUT_FILE=/dev/null",
            image,
        ]
    )
    container = container.decode().strip()
    ip_port = subprocess.check_output(["docker", "port", container, "9600"])
    ip_port = ip_port.decode().strip()

    host, port = ip_port.split(":")
    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
        sock.settimeout(60)
        assert sock.connect_ex((host, int(port))) == 0
    subprocess.check_call(["docker", "stop", container])
    subprocess.check_call(["docker", "rm", container])
